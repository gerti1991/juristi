"""
Enhanced Albanian Legal RAG System with Cloud LLM Integration
Now uses Groq API for advanced response generation with environment variables
"""

import os
import streamlit as st
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import json
from datetime import datetime
from scraper import AlbanianLegalScraper
from ai import CloudLLMClient
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Set environment variables for PyTorch compatibility
os.environ['TORCH_SHOW_CPP_STACKTRACES'] = '0'
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'

class CloudEnhancedAlbanianLegalRAG:
    def __init__(self):
        """Initialize the cloud-enhanced RAG system with environment variables"""
        self.model_name = 'all-MiniLM-L6-v2'
        self.model = None
        self.legal_documents = []
        self.document_embeddings = None
        self.scraper = AlbanianLegalScraper(max_docs=10)
        self.cloud_llm = None
        
        # Configuration from environment variables
        self.similarity_threshold = float(os.getenv('SIMILARITY_THRESHOLD', '0.08'))
        self.max_context_length = int(os.getenv('MAX_CONTEXT_LENGTH', '4000'))
        self.max_chunks_to_return = int(os.getenv('MAX_CHUNKS_TO_RETURN', '5'))
        
        # Cache file for embeddings
        self.embeddings_cache_file = 'document_embeddings_cache.json'
        
        # Load model with error handling
        self._load_model()
        
        # Initialize cloud LLM
        self._load_cloud_llm()
        
        # Initialize document collection
        self._load_all_documents()
        
        # Generate embeddings
        self._generate_embeddings()
    
    def _load_model(self):
        """Load the sentence transformer model with error handling"""
        try:
            st.info("ğŸ”„ Loading AI model...")
            self.model = SentenceTransformer(self.model_name)
            st.success("âœ… AI model loaded successfully!")
        except Exception as e:
            st.error(f"âŒ Error loading model: {e}")
            st.info("Please ensure sentence-transformers is installed: pip install sentence-transformers")
            self.model = None
    
    def _load_cloud_llm(self):
        """Initialize cloud LLM client"""
        try:
            st.info("ğŸŒ Connecting to cloud LLM...")
            self.cloud_llm = CloudLLMClient("groq")
            
            if self.cloud_llm.api_key:
                st.success("âœ… Cloud LLM connected successfully!")
                st.info(f"ğŸ¤– Using model: {self.cloud_llm.model}")
            else:
                st.warning("âš ï¸ Cloud LLM API key not found - using fallback responses")
        except Exception as e:
            st.error(f"âŒ Cloud LLM connection error: {e}")
            st.info("Will use template-based responses as fallback")
            self.cloud_llm = None
    
    def _load_hardcoded_documents(self):
        """Load the original hardcoded legal documents"""
        hardcoded_docs = [
            {
                "id": "family_law_1",
                "title": "Kodi i Familjes - Family Code",
                "source": "Albanian Family Code",
                "content": "Kodi i Familjes rregullon marrÃ«dhÃ«niet familjare, martesÃ«n, divorci, dhe tÃ« drejtat e fÃ«mijÃ«ve nÃ« ShqipÃ«ri.",
                "content_en": "The Family Code regulates family relationships, marriage, divorce, and children's rights in Albania.",
                "document_type": "hardcoded"
            },
            {
                "id": "property_law_1", 
                "title": "Ligji i PronÃ«sisÃ« - Property Law",
                "source": "Albanian Property Law",
                "content": "Ligji i pronÃ«sisÃ« nÃ« ShqipÃ«ri rregullon tÃ« drejtÃ«n e pronÃ«sisÃ« private, publike dhe transferimin e pronave.",
                "content_en": "Property law in Albania regulates private property rights, public property and property transfers.",
                "document_type": "hardcoded"
            },
            {
                "id": "labor_law_1",
                "title": "Kodi i PunÃ«s - Labor Code", 
                "source": "Albanian Labor Code",
                "content": "Kodi i PunÃ«s rregullon marrÃ«dhÃ«niet e punÃ«s, tÃ« drejtat dhe detyrimet e punÃ«dhÃ«nÃ«sve dhe tÃ« punÃ«suarve. Ã‡do punÃ«tor ka tÃ« drejtÃ« pÃ«r pushim vjetor me pagesÃ«. Pushimi vjetor Ã«shtÃ« gjithsej 28 ditÃ« kalendarike nÃ« vit, nga tÃ« cilat 14 ditÃ« janÃ« tÃ« detyrueshme dhe duhet tÃ« merren gjatÃ« vitit. DitÃ«t e tjera mund tÃ« transferohen nÃ« vitin tjetÃ«r me marrÃ«veshje me punÃ«dhÃ«nÃ«sin.",
                "content_en": "The Labor Code regulates employment relationships, rights and obligations of employers and employees. Every worker has the right to paid annual leave. Annual leave is a total of 28 calendar days per year, of which 14 days are mandatory and must be taken during the year. Other days can be transferred to the next year by agreement with the employer.",
                "document_type": "hardcoded"
            },
            {
                "id": "criminal_law_1",
                "title": "Kodi Penal - Criminal Code",
                "source": "Albanian Criminal Code", 
                "content": "Kodi Penal i ShqipÃ«risÃ« pÃ«rcakton veprat penale dhe sanksionet pÃ«rkatÃ«se pÃ«r to.",
                "content_en": "Albania's Criminal Code defines criminal acts and their corresponding sanctions.",
                "document_type": "hardcoded"
            },
            {
                "id": "business_law_1",
                "title": "Ligji pÃ«r Biznesin - Business Law",
                "source": "Albanian Business Law",
                "content": "Ligji pÃ«r biznesin rregullon themelimin, funksionimin dhe mbylljen e shoqÃ«rive tregtare nÃ« ShqipÃ«ri.",
                "content_en": "Business law regulates the establishment, operation and closure of commercial companies in Albania.",
                "document_type": "hardcoded"
            },
            {
                "id": "civil_code_1",
                "title": "Kodi Civil - Civil Code",
                "source": "Albanian Civil Code",
                "content": "Kodi Civil rregullon tÃ« drejtat dhe detyrimet civile, kontrata dhe pÃ«rgjegjÃ«sinÃ« civile.",
                "content_en": "The Civil Code regulates civil rights and obligations, contracts and civil liability.",
                "document_type": "hardcoded"
            },
            {
                "id": "constitution_1",
                "title": "Kushtetuta e ShqipÃ«risÃ« - Albanian Constitution", 
                "source": "Albanian Constitution",
                "content": "Kushtetuta Ã«shtÃ« ligji mÃ« i lartÃ« i vendit dhe garanton tÃ« drejtat dhe liritÃ« themelore tÃ« qytetarÃ«ve.",
                "content_en": "The Constitution is the highest law of the country and guarantees fundamental rights and freedoms of citizens.",
                "document_type": "hardcoded"
            },
            {
                "id": "tax_law_1",
                "title": "Ligji pÃ«r Taksat - Tax Law",
                "source": "Albanian Tax Law", 
                "content": "Ligji pÃ«r taksat rregullon sistemin tatimor, detyrimet tatimore dhe procedurat e mbledhjes sÃ« taksave.",
                "content_en": "Tax law regulates the tax system, tax obligations and tax collection procedures.",
                "document_type": "hardcoded"
            }
        ]
        
        return hardcoded_docs
    
    def _load_scraped_documents(self):
        """Load documents scraped from qbz.gov.al"""
        try:
            scraped_docs = self.scraper.get_processed_documents_for_rag()
            st.info(f"ğŸ“„ Loaded {len(scraped_docs)} scraped document chunks")
            return scraped_docs
        except Exception as e:
            st.warning(f"âš ï¸ Could not load scraped documents: {e}")
            return []
    
    def _load_pdf_documents(self):
        """Load processed PDF documents"""
        try:
            pdf_file = os.path.join("legal_documents", "pdf_rag_documents.json")
            if os.path.exists(pdf_file):
                with open(pdf_file, 'r', encoding='utf-8') as f:
                    pdf_docs = json.load(f)
                
                # Normalize PDF documents to match expected format
                normalized_docs = []
                for doc in pdf_docs:
                    normalized_doc = {
                        'title': doc.get('title', 'Unknown Document'),
                        'content': doc.get('content', ''),
                        'source': doc.get('filename', doc.get('source_url', 'Local PDF')),
                        'url': doc.get('source_url', ''),
                        'document_type': 'local_pdf'
                    }
                    normalized_docs.append(normalized_doc)
                
                st.info(f"ğŸ“„ Loaded {len(normalized_docs)} PDF document chunks")
                return normalized_docs
            else:
                st.warning("âš ï¸ No processed PDF documents found")
                return []
        except Exception as e:
            st.warning(f"âš ï¸ Could not load PDF documents: {e}")
            return []
    
    def _load_all_documents(self):
        """Load hardcoded, scraped, and PDF documents"""
        # Load hardcoded documents
        hardcoded = self._load_hardcoded_documents()
        
        # Load scraped documents
        scraped = self._load_scraped_documents()
        
        # Load PDF documents
        pdf_docs = self._load_pdf_documents()
        
        # Combine all documents
        self.legal_documents = hardcoded + scraped + pdf_docs
        
        st.info(f"ğŸ“š Total documents loaded: {len(self.legal_documents)} "
                f"({len(hardcoded)} hardcoded + {len(scraped)} scraped + {len(pdf_docs)} PDF)")
    
    def _load_embeddings_cache(self):
        """Load cached embeddings if available"""
        if os.path.exists(self.embeddings_cache_file):
            try:
                with open(self.embeddings_cache_file, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
                
                # Check if cache is still valid (same number of documents)
                if cache.get('document_count') == len(self.legal_documents):
                    self.document_embeddings = np.array(cache['embeddings'])
                    st.success("âœ… Loaded cached embeddings")
                    return True
            except Exception as e:
                st.warning(f"âš ï¸ Could not load embedding cache: {e}")
        
        return False
    
    def _save_embeddings_cache(self):
        """Save embeddings to cache"""
        try:
            cache = {
                'embeddings': self.document_embeddings.tolist(),
                'document_count': len(self.legal_documents),
                'created_at': datetime.now().isoformat()
            }
            
            with open(self.embeddings_cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache, f)
                
            st.success("âœ… Embeddings cached for faster loading")
        except Exception as e:
            st.warning(f"âš ï¸ Could not save embedding cache: {e}")
    
    def _generate_embeddings(self):
        """Generate embeddings for all documents"""
        if not self.model:
            st.error("âŒ Model not loaded - cannot generate embeddings")
            return
        
        if not self.legal_documents:
            st.error("âŒ No documents loaded - cannot generate embeddings")
            return
        
        # Try to load from cache first
        if self._load_embeddings_cache():
            return
        
        try:
            st.info("ğŸ”„ Generating document embeddings...")
            
            # Combine Albanian and English content for better matching
            document_texts = []
            for doc in self.legal_documents:
                combined_text = f"{doc['content']} {doc.get('content_en', '')}"
                document_texts.append(combined_text)
            
            # Generate embeddings
            self.document_embeddings = self.model.encode(document_texts)
            
            # Save to cache
            self._save_embeddings_cache()
            
            st.success(f"âœ… Generated embeddings for {len(self.legal_documents)} documents")
            
        except Exception as e:
            st.error(f"âŒ Error generating embeddings: {e}")
            self.document_embeddings = None
    
    def search_documents(self, query: str, top_k: int = 3):
        """Search for relevant documents using semantic similarity with Albanian query enhancement"""
        if not self.model or self.document_embeddings is None:
            return []
        
        try:
            # Enhance Albanian queries for better semantic search
            enhanced_query = self._enhance_albanian_query(query)
            
            # Generate query embedding
            query_embedding = self.model.encode([enhanced_query])
            
            # Calculate similarities
            similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]
            
            # Get top matches
            top_indices = np.argsort(similarities)[::-1][:top_k]
            
            results = []
            max_similarity = 0
            for idx in top_indices:
                similarity = float(similarities[idx])
                if similarity > max_similarity:
                    max_similarity = similarity
                if similarity > self.similarity_threshold:  # Configurable threshold for Albanian queries
                    doc = self.legal_documents[idx].copy()
                    doc['similarity'] = similarity
                    results.append(doc)
            
            # Store max similarity for fallback decision
            self.last_search_max_similarity = max_similarity
            
            return results
            
        except Exception as e:
            st.error(f"âŒ Search error: {e}")
            return []
    
    def _enhance_albanian_query(self, query: str) -> str:
        """Enhance Albanian queries with synonyms and related terms"""
        enhanced_query = query
        
        # Add Albanian legal synonyms
        legal_synonyms = {
            'pushim': 'pushim leaves vacation dit',
            'punÃ«': 'punÃ« work employment job',
            'ligj': 'ligj law legal kod',
            'sanksion': 'sanksion penalty dÃ«nim gjobÃ«',
            'kompani': 'kompani company business shoqÃ«ri',
            'kontrata': 'kontrata contract marrÃ«veshje',
            'vjedhje': 'vjedhje theft stealing',
            'martesÃ«': 'martesÃ« marriage bashkÃ«short',
            'divorcÃ«': 'divorcÃ« divorce ndarje'
        }
        
        for albanian_term, synonyms in legal_synonyms.items():
            if albanian_term in query.lower():
                enhanced_query += f" {synonyms}"
        
        return enhanced_query
    
    def generate_response(self, query: str, relevant_docs: list) -> str:
        """Generate a comprehensive response using cloud LLM or fallback"""
        if self.cloud_llm and self.cloud_llm.api_key:
            try:
                # Use cloud LLM for advanced response generation
                return self.cloud_llm.generate_response(query, relevant_docs)
            except Exception as e:
                st.warning(f"âš ï¸ Cloud LLM error, using fallback: {e}")
                return self._fallback_response(query, relevant_docs)
        else:
            # Use fallback response
            return self._fallback_response(query, relevant_docs)
    
    def _fallback_response(self, query: str, relevant_docs: list) -> str:
        """Fallback response when cloud LLM is not available"""
        if not relevant_docs:
            return self._get_no_results_response()
        
        # Check for vacation-related queries
        vacation_keywords = ['pushim', 'pushimi', 'vacation', 'leave', 'dit']
        if any(keyword in query.lower() for keyword in vacation_keywords):
            return self._get_vacation_response(relevant_docs)
        
        # General response
        response = "Bazuar nÃ« dokumentet ligjore shqiptare:\n\n"
        
        for i, doc in enumerate(relevant_docs, 1):
            doc_type_indicator = "ğŸŒ" if doc.get('document_type') == 'scraped_legal_document' else "ğŸ“š"
            response += f"{doc_type_indicator} **{doc['title']}** (Relevanca: {doc['similarity']:.2f})\n"
            response += f"{doc['content'][:300]}...\n\n"
        
        response += "\n---\n**ShÃ«nim**: Ky pÃ«rgjigje Ã«shtÃ« bazuar nÃ« dokumentet e disponueshme. "
        response += "PÃ«r kÃ«shilla tÃ« detajuara ligjore, konsultohuni me njÃ« jurist tÃ« kualifikuar."
        
        return response
    
    def _get_vacation_response(self, relevant_docs: list) -> str:
        """Generate specific response for vacation-related queries"""
        response = "ğŸ–ï¸ **Informacion mbi Pushimin Vjetor nÃ« ShqipÃ«ri**\n\n"
        
        response += "Sipas Kodit tÃ« PunÃ«s sÃ« ShqipÃ«risÃ«:\n\n"
        response += "ğŸ“… **Pushimi Vjetor Total**: 28 ditÃ« kalendarike nÃ« vit\n"
        response += "âš ï¸ **Pushimi i DetyrueshÃ«m**: 14 ditÃ« qÃ« duhet tÃ« merren gjatÃ« vitit\n"
        response += "ğŸ”„ **Pushimi Opsional**: 14 ditÃ« tÃ« tjera mund tÃ« transferohen nÃ« vitin tjetÃ«r\n"
        response += "ğŸ’° **Pushimi me PagesÃ«**: Po, pushimi vjetor Ã«shtÃ« me pagesÃ« tÃ« plotÃ«\n\n"
        
        response += "ğŸ“‹ **Detaje tÃ« RÃ«ndÃ«sishme**:\n"
        response += "â€¢ TÃ« gjithÃ« punÃ«torÃ«t kanÃ« tÃ« drejtÃ« pÃ«r pushim vjetor\n"
        response += "â€¢ Pushimi planifikohet nÃ« marrÃ«veshje me punÃ«dhÃ«nÃ«sin\n"
        response += "â€¢ 14 ditÃ«t e detyrueshme nuk mund tÃ« zÃ«vendÃ«sohen me pagesÃ«\n"
        response += "â€¢ DitÃ«t e tjera mund tÃ« akumulohen me marrÃ«veshje\n\n"
        
        # Add relevant document excerpts
        for doc in relevant_docs[:2]:
            if 'labor' in doc.get('id', '').lower() or 'punÃ«' in doc.get('content', '').lower():
                doc_type = "ğŸŒ" if doc.get('document_type') == 'scraped_legal_document' else "ğŸ“š"
                response += f"{doc_type} **Burim**: {doc['title']}\n"
                response += f"ğŸ“– {doc['content'][:200]}...\n\n"
        
        response += "\n---\nâš–ï¸ **KÃ«shillÃ« Ligjore**: PÃ«r situata tÃ« veÃ§anta ose mosmarrÃ«veshje, "
        response += "konsultohuni me njÃ« jurist tÃ« specializuar nÃ« tÃ« drejtÃ«n e punÃ«s."
        
        return response
    
    def _get_no_results_response(self) -> str:
        """Response when no relevant documents are found"""
        return """
        ğŸ¤” **Nuk u gjetÃ«n dokumente specifike pÃ«r kÃ«tÃ« pyetje.**
        
        Ju lutem provoni:
        â€¢ PÃ«rdorni fjalÃ« kyÃ§e tÃ« tjera
        â€¢ BÃ«ni pyetjen mÃ« tÃ« qartÃ«
        â€¢ Kontrolloni drejtshkrimin
        
        ğŸ“š Ose eksploro temat e disponueshme:
        â€¢ Kodi i Familjes
        â€¢ Ligji i PronÃ«sisÃ«  
        â€¢ Kodi i PunÃ«s
        â€¢ Kodi Penal
        â€¢ Ligji pÃ«r Biznesin
        â€¢ Kodi Civil
        â€¢ Kushtetuta e ShqipÃ«risÃ«
        â€¢ Ligji pÃ«r Taksat
        
        Gjithashtu disponojmÃ« dokumente tÃ« pÃ«rditÃ«suara nga qbz.gov.al
        """
    
    def scrape_new_documents(self):
        """Scrape new documents and update the system"""
        with st.spinner("ğŸ”„ Duke shkarkuar dokumente tÃ« reja nga qbz.gov.al..."):
            try:
                # Scrape new documents
                found_docs = self.scraper.scrape_qbz_search(['ligj', 'kod', 'vendim'])
                
                if found_docs:
                    st.success(f"ğŸ“¥ U shkarkuan {len(found_docs)} dokumente tÃ« reja")
                    
                    # Process the documents
                    with st.spinner("ğŸ“– Duke pÃ«rpunuar dokumentet..."):
                        processed = self.scraper.process_downloaded_documents()
                        st.success(f"âœ… U pÃ«rpunuan {len(processed)} dokumente")
                    
                    # Reload all documents
                    self._load_all_documents()
                    
                    # Regenerate embeddings
                    self._generate_embeddings()
                    
                    st.success("ğŸ‰ Sistemi u pÃ«rditÃ«sua me dokumente tÃ« reja!")
                    return True
                else:
                    st.info("â„¹ï¸ Nuk u gjetÃ«n dokumente tÃ« reja")
                    return False
                    
            except Exception as e:
                st.error(f"âŒ Gabim gjatÃ« shkarkimit: {e}")
                return False


def main():
    """Main Streamlit application"""
    st.set_page_config(
        page_title="Albanian Legal RAG System", 
        page_icon="âš–ï¸",
        layout="wide"
    )
    
    # Header
    st.title("âš–ï¸ Sistemi Shqiptar i Ligjit me AI")
    st.markdown("### ğŸ¤– Intelligent Legal Research Assistant for Albanian Law")
    st.markdown("#### ğŸŒ Now powered by advanced cloud AI (Groq API)")
    
    # Initialize session state
    if 'rag_system' not in st.session_state:
        with st.spinner("ğŸ”„ Duke inicializuar sistemin..."):
            st.session_state.rag_system = CloudEnhancedAlbanianLegalRAG()
    
    rag_system = st.session_state.rag_system
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ› ï¸ Kontrollet e Sistemit")
        
        # Document statistics
        total_docs = len(rag_system.legal_documents)
        hardcoded_count = len([d for d in rag_system.legal_documents if d.get('document_type') == 'hardcoded'])
        scraped_count = total_docs - hardcoded_count
        
        st.metric("ğŸ“š Total Dokumente", total_docs)
        st.metric("ğŸ“– Dokumente BazÃ«", hardcoded_count)
        st.metric("ğŸŒ Dokumente tÃ« Shkarkuara", scraped_count)
        
        # Cloud LLM status
        st.divider()
        st.subheader("ğŸŒ Cloud AI Status")
        if rag_system.cloud_llm and rag_system.cloud_llm.api_key:
            st.success("âœ… Cloud AI Connected")
            st.info(f"ğŸ¤– Model: {rag_system.cloud_llm.model}")
        else:
            st.warning("âš ï¸ Using Fallback Responses")
        
        st.divider()
        
        # Scraping controls
        st.subheader("ğŸ”„ PÃ«rditÃ«sim Dokumentesh")
        
        if st.button("ğŸŒ Shkarko Dokumente tÃ« Reja", type="primary"):
            rag_system.scrape_new_documents()
        
        st.caption("Shkarkon dokumente tÃ« reja nga qbz.gov.al")
        
        st.divider()
        
        # Help section
        st.subheader("â“ Si tÃ« PÃ«rdorni")
        st.write("""
        1. **Shkruani pyetjen tuaj** nÃ« shqip ose anglisht
        2. **Shtypni Enter** ose klikoni KÃ«rko
        3. **Lexoni pÃ«rgjigjen** e bazuar nÃ« ligjet shqiptare
        4. **PÃ«rdorni "Shkarko Dokumente"** pÃ«r pÃ«rditÃ«sime
        
        **ğŸŒ E re**: PÃ«rgjigjet tani gjenerohen nga AI i avancuar!
        """)
        
        # Examples
        st.subheader("ğŸ’¡ Shembuj Pyetjesh")
        example_queries = [
            "Sa dit pushimi kam nÃ« punÃ« tÃ« detyrueshme?",
            "Si themeloj njÃ« biznes nÃ« ShqipÃ«ri?",
            "Cilat janÃ« tÃ« drejtat e fÃ«mijÃ«ve?",
            "Si funksionon procedura e divorcit?",
            "Ã‡farÃ« taksash duhet tÃ« paguaj?"
        ]
        
        for query in example_queries:
            if st.button(f"ğŸ’¬ {query}", key=f"example_{hash(query)}"):
                st.session_state.example_query = query
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ BÃ«ni Pyetjen Tuaj")
        
        # Query input
        default_query = st.session_state.get('example_query', '')
        query = st.text_area(
            "Shkruani pyetjen tuaj ligjore:",
            value=default_query,
            placeholder="P.sh. Sa dit pushimi kam nÃ« punÃ« tÃ« detyrueshme?",
            height=100
        )
        
        # Clear example query after use
        if 'example_query' in st.session_state:
            del st.session_state.example_query
        
        # Search button
        if st.button("ğŸ” KÃ«rko PÃ«rgjigje", type="primary") or query:
            if query.strip():
                with st.spinner("ğŸ” Duke kÃ«rkuar nÃ« dokumentet ligjore..."):
                    # Search for relevant documents
                    relevant_docs = rag_system.search_documents(query, top_k=3)
                    
                    # Generate response
                    with st.spinner("ğŸ¤– Duke gjeneruar pÃ«rgjigje me AI..."):
                        response = rag_system.generate_response(query, relevant_docs)
                    
                    # Display response
                    st.subheader("ğŸ“‹ PÃ«rgjigja")
                    st.markdown(response)
                    
                    # Show source documents
                    if relevant_docs:
                        with st.expander("ğŸ“š Dokumentet e PÃ«rdorura", expanded=False):
                            for i, doc in enumerate(relevant_docs, 1):
                                # Determine document type with safe access
                                doc_type = "ğŸŒ Dokument i shkarkuar" if doc.get('document_type') == 'scraped_legal_document' else \
                                          "ï¿½ PDF Document" if doc.get('document_type') == 'local_pdf' else \
                                          "ï¿½ğŸ“š Dokument bazÃ«"
                                
                                st.write(f"**{i}. {doc.get('title', 'Unknown Title')}** ({doc_type})")
                                st.write(f"Relevanca: {doc.get('similarity', 0):.2%}")
                                
                                # Safe access to source field
                                source = doc.get('source', doc.get('filename', doc.get('source_url', 'Unknown Source')))
                                st.write(f"Burimi: {source}")
                                
                                if doc.get('url'):
                                    st.write(f"URL: {doc['url']}")
                                st.write("---")
                    else:
                        # No relevant documents found
                        st.info("â„¹ï¸ **AsnjÃ« dokument specifik nuk u gjet pÃ«r kÃ«tÃ« pyetje**")
                        st.write("PÃ«rgjigja e mÃ«sipÃ«rme Ã«shtÃ« bazuar nÃ« njohuritÃ« e pÃ«rgjithshme pÃ«r tÃ« drejtÃ«n shqiptare.")
                        st.write("ğŸ’¡ **Sugjerim**: Kontaktoni njÃ« jurist tÃ« kualifikuar pÃ«r kÃ«shilla tÃ« detajuara ligjore.")
            else:
                st.warning("âš ï¸ Ju lutem shkruani njÃ« pyetje")
    
    with col2:
        st.header("ğŸ“Š Statistika Sistemi")
        
        # System status
        model_status = "âœ… I ngarkuar" if rag_system.model else "âŒ Gabim"
        embeddings_status = "âœ… Gati" if rag_system.document_embeddings is not None else "âŒ MungojnÃ«"
        cloud_status = "âœ… I lidhur" if rag_system.cloud_llm and rag_system.cloud_llm.api_key else "âš ï¸ Fallback"
        
        st.metric("ğŸ¤– Modeli AI", model_status)
        st.metric("ğŸ”¢ Embeddings", embeddings_status)
        st.metric("ğŸŒ Cloud AI", cloud_status)
        
        if rag_system.document_embeddings is not None:
            embedding_shape = rag_system.document_embeddings.shape
            st.caption(f"Dimensioni: {embedding_shape[0]}Ã—{embedding_shape[1]}")
        
        # Last update info
        if os.path.exists(rag_system.scraper.metadata_file):
            try:
                with open(rag_system.scraper.metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    if metadata.get('last_updated'):
                        last_update = datetime.fromisoformat(metadata['last_updated'])
                        st.metric("ğŸ•’ PÃ«rditÃ«simi i Fundit", last_update.strftime("%d/%m/%Y %H:%M"))
            except:
                pass
        
        # Performance metrics
        st.subheader("âš¡ Performance")
        st.metric("ğŸ“ˆ Dokumente Aktive", len(rag_system.legal_documents))
        
        # Quick stats about document types
        doc_types = {}
        for doc in rag_system.legal_documents:
            doc_type = doc.get('document_type', 'unknown')
            doc_types[doc_type] = doc_types.get(doc_type, 0) + 1
        
        for doc_type, count in doc_types.items():
            if doc_type == 'hardcoded':
                st.metric("ğŸ“– BazÃ«", count)
            elif doc_type == 'scraped_legal_document':
                st.metric("ğŸŒ TÃ« shkarkuara", count)
    
    # Footer
    st.divider()
    st.caption("âš–ï¸ Albanian Legal RAG System - Now powered by Advanced Cloud AI (Groq)")
    st.caption("ğŸ”„ Automatically updates with latest documents from qbz.gov.al")


if __name__ == "__main__":
    main()
