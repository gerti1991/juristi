"""
Cloud LLM Integration for Albanian Legal RAG System
Support for Groq API, Google Gemini, and other providers
"""

import os
import requests
import json
from typing import List, Dict, Optional
import time
from dotenv import load_dotenv
import google.generativeai as genai

# Load environment variables from .env file
load_dotenv()

class CloudLLMClient:
    """Client for cloud-based LLM services supporting multiple providers"""
    
    def __init__(self, provider="gemini"):
        """Initialize cloud LLM client with environment variables"""
        self.provider = provider
        self.current_provider = provider  # Add missing attribute
        self.api_key = self._get_api_key()
        self.base_url = self._get_base_url()
        self.model = self._get_model()
        
        # Initialize Gemini client if needed
        if self.provider == "gemini" and self.api_key:
            try:
                genai.configure(api_key=self.api_key)
                self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
            except Exception as e:
                print(f"Warning: Could not initialize Gemini: {e}")
                self.gemini_model = None
        else:
            self.gemini_model = None
        
    def _get_api_key(self) -> str:
        """Get API key from environment or config"""
        if self.provider == "gemini":
            api_key = os.getenv("GEMINI_API_KEY")
            if not api_key:
                # Check config.py
                try:
                    import config
                    api_key = getattr(config, 'GEMINI_API_KEY', None)
                except ImportError:
                    pass
                
                if not api_key:
                    print("âš ï¸ GEMINI_API_KEY not found! Get your free API key from: https://aistudio.google.com/app/apikey")
                    return ""
            return api_key
        elif self.provider == "groq":
            api_key = os.getenv("GROQ_API_KEY")
            if not api_key:
                # Check config.py
                try:
                    import config
                    api_key = getattr(config, 'GROQ_API_KEY', None)
                except ImportError:
                    pass
                
                if not api_key:
                    raise ValueError("âš ï¸ GROQ_API_KEY not found! Please set it in config.py or environment variable.")
            return api_key
        elif self.provider == "huggingface":
            return os.getenv("HUGGINGFACE_API_KEY", "")
        else:
            return ""
    
    def _get_base_url(self) -> str:
        """Get base URL for the provider"""
        if self.provider == "gemini":
            return "https://generativelanguage.googleapis.com/v1beta/models"
        elif self.provider == "groq":
            return "https://api.groq.com/openai/v1/chat/completions"
        elif self.provider == "huggingface":
            return "https://api-inference.huggingface.co/models/"
        else:
            return ""
    
    def _get_model(self) -> str:
        """Get model name for the provider"""
        if self.provider == "gemini":
            return "gemini-2.0-flash-exp"  # Free and powerful model
        elif self.provider == "groq":
            return "llama3-8b-8192"  # Fast and good for legal tasks
        elif self.provider == "huggingface":
            return "microsoft/DialoGPT-large"
        else:
            return ""
    
    def generate_response(self, query: str, relevant_docs: List[Dict], context: str = "") -> str:
        """Generate enhanced response using cloud LLM with fallback for no documents"""
        
        if not self.api_key:
            return self._fallback_response(query, relevant_docs)

        try:
            # Check if we have relevant documents
            if not relevant_docs or len(relevant_docs) == 0:
                # Use LLM's general knowledge for Albanian legal questions
                prompt = self._create_general_legal_prompt(query)
                print("â„¹ï¸ Nuk u gjetÃ«n dokumente specifike, duke pÃ«rdorur njohuritÃ« e pÃ«rgjithshme ligjore")
            else:
                # Use documents + LLM knowledge
                prompt = self._create_legal_prompt(query, relevant_docs, context)
            
            if self.provider == "gemini":
                return self._gemini_request(prompt)
            elif self.provider == "groq":
                return self._groq_request(prompt)
            elif self.provider == "huggingface":
                return self._huggingface_request(prompt)
            else:
                return self._fallback_response(query, relevant_docs)
                
        except Exception as e:
            print(f"âŒ Cloud LLM error: {e}")
            return self._fallback_response(query, relevant_docs)
    
    def _create_general_legal_prompt(self, query: str) -> str:
        """Create prompt for general legal knowledge when no documents found"""
        prompt = f"""
Je njÃ« jurist i specializuar pÃ«r tÃ« drejtÃ«n shqiptare. NjÃ« person tÃ« pyet:

PYETJA: {query}

MeqenÃ«se nuk gjeta dokumente specifike nÃ« bazÃ«n e tÃ« dhÃ«nave, pÃ«rdor njohuritÃ« e tua tÃ« pÃ«rgjithshme pÃ«r tÃ« drejtÃ«n shqiptare pÃ«r t'u pÃ«rgjigjur.

UDHÃ‹ZIME:
1. PÃ«rgjigju nÃ« shqip
2. Jep informacion tÃ« pÃ«rgjithshÃ«m pÃ«r sistemin ligjor shqiptar
3. Sugjeroi qÃ« personi tÃ« kontaktojÃ« njÃ« jurist tÃ« kualifikuar pÃ«r kÃ«shilla specifike
4. Mos jep kÃ«shilla tÃ« detajuara ligjore pa dokumente specifike
5. TÃ« jesh i sinqertÃ« qÃ« informacioni Ã«shtÃ« i pÃ«rgjithshÃ«m

PÃ‹RGJIGJJA:
"""
        return prompt
    
    def _create_legal_prompt(self, query: str, relevant_docs: List[Dict], context: str = "") -> str:
        """Create a comprehensive legal analysis prompt that synthesizes multiple documents"""
        
        # Extract key information from documents
        legal_sources = []
        all_articles = []
        
        for doc in relevant_docs[:5]:  # Use top 5 most relevant documents
            title = doc.get('title', 'Dokument pa titull')
            content = doc.get('content', '')
            source = doc.get('source', 'Pa burim')
            
            # Extract law codes and articles
            import re
            articles = re.findall(r'[Nn]eni\s*\d+[a-z]*', content)
            all_articles.extend(articles)
            
            legal_sources.append({
                'title': title,
                'source': source,
                'content': content[:800],  # Limit content length but keep substantial info
                'articles': articles[:3] if articles else []
            })
        
        # Build comprehensive synthesis prompt
        sources_text = ""
        for i, source in enumerate(legal_sources, 1):
            sources_text += f"""
DOKUMENTI {i}: {source['title']}
Burimi: {source['source']}
Nenet e pÃ«rfshira: {', '.join(source['articles']) if source['articles'] else 'TÃ« ndryshme'}

PÃ«rmbajtja:
{source['content']}

---"""
        
        prompt = f"""Ti je njÃ« ekspert i lartÃ« i sÃ« drejtÃ«s shqiptare me dekada pÃ«rvojÃ« nÃ« interpretimin e legjislacionit shqiptar. TÃ« jepet njÃ« pyetje ligjore dhe disa dokumente relevante.

PYETJA E KLIENTIT: {query}

DOKUMENTET LIGJORE PÃ‹R ANALIZÃ‹:
{sources_text}

DETYRA JOTE:
Krijo njÃ« analizÃ« tÃ« plotÃ« juridike qÃ« SINTETIZON tÃ« gjitha dokumentet e mÃ«sipÃ«rme pÃ«r tÃ« dhÃ«nÃ« njÃ« pÃ«rgjigje tÃ« vetme, koherente dhe autoritare. 

STRUKTURA E PÃ‹RGJIGJES:

ðŸŽ¯ **PÃ‹RGJIGJJA E DREJTPÃ‹RDREJTÃ‹**
Jep njÃ« pÃ«rgjigje tÃ« qartÃ« dhe konkrete pÃ«r pyetjen e bÃ«rÃ«.

âš–ï¸ **BAZAT LIGJORE**
Lista tÃ« gjitha nenet, kodet dhe ligjet relevante nga dokumentet e analizuara.

ðŸ“– **ANALIZA JURIDIKE** 
Shpjego logjikÃ«n ligjore duke kombinuar informacionin nga tÃ« gjitha dokumentet. Trego se si ligjet e ndryshme lidhen dhe ndikojnÃ« tek njÃ«ra-tjetra.

âš ï¸ **RASTE TÃ‹ VEÃ‡ANTA & PÃ‹RJASHTIME**
NÃ«se ka pÃ«rjashtime, kushte tÃ« veÃ§anta ose nuanca tÃ« rÃ«ndÃ«sishme.

ðŸ›ï¸ **KÃ‹SHILLA PRAKTIKE**
Sugjerime konkrete pÃ«r personin qÃ« pyet.

ðŸ“‹ **HAPA TÃ‹ MÃ‹TEJSHÃ‹M**
Ã‡farÃ« duhet tÃ« bÃ«jÃ« personi nÃ« vazhdim.

RREGULLA TÃ‹ RÃ‹NDÃ‹SISHME:
- PÃ«rdor VETÃ‹M informacionin nga dokumentet e dhÃ«na
- SINTETIZO dokumentet pÃ«r tÃ« krijuar njÃ« pÃ«rgjigje tÃ« vetme koherente
- MOS listosh dokumente individualisht - kombinoji ato
- PÃ«rdor gjuhÃ«n shqipe profesionale dhe tÃ« qartÃ«
- Jep njÃ« pÃ«rgjigje autoritare dhe tÃ« sigurt
- NÃ«se ka informacion kontraditor, shpjegoje qartÃ«

FORMATI: PÃ«rdor emoji dhe formatim tÃ« qartÃ« si nÃ« strukturÃ«n e mÃ«sipÃ«rme."""
        
        return prompt
    
    def _groq_request(self, prompt: str) -> str:
        """Make request to Groq API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": "Je njÃ« asistent i specializuar pÃ«r tÃ« drejtÃ«n shqiptare. PÃ«rgjigju nÃ« mÃ«nyrÃ« tÃ« saktÃ« dhe profesionale."
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "max_tokens": 1000,
            "temperature": 0.2,
            "stream": False
        }
        
        response = requests.post(
            self.base_url,
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result["choices"][0]["message"]["content"]
        else:
            error_msg = f"Groq API error: {response.status_code}"
            print(error_msg)
            return f"Na vjen keq, ndodhi njÃ« gabim: {error_msg}"
    
    def _gemini_request(self, prompt: str) -> str:
        """Make request to Google Gemini API"""
        if not self.gemini_model:
            return self._fallback_response("", [])
            
        try:
            response = self.gemini_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.2,
                    max_output_tokens=1000,
                )
            )
            return response.text
        except Exception as e:
            print(f"Gemini API error: {e}")
            return f"Na vjen keq, ndodhi njÃ« gabim me Gemini API: {e}"
    
    def _huggingface_request(self, prompt: str) -> str:
        """Make request to Hugging Face API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_length": 500,
                "temperature": 0.3,
                "return_full_text": False
            }
        }
        
        response = requests.post(
            f"{self.base_url}{self.model}",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                return result[0].get('generated_text', 'Nuk u gjend pÃ«rgjigje.')
            return 'PÃ«rgjigje e pavlefshme nga API.'
        else:
            return f"Gabim API: {response.status_code}"
    
    def _fallback_response(self, query: str, relevant_docs: List[Dict]) -> str:
        """Provide template-based fallback response"""
        if not relevant_docs:
            return """
ðŸ›ï¸ **Sistemi Ligjor Shqiptar - Informacion i PÃ«rgjithshÃ«m**

Na vjen keq, nuk gjeta dokumente specifike pÃ«r pyetjen tuaj. Ja disa sugjerime:

ðŸ“š **PÃ«r informacion tÃ« detajuar ligjor:**
- Vizitoni faqen zyrtare: qbz.gov.al
- Kontaktoni njÃ« jurist tÃ« kualifikuar
- Konsultohuni me DhomÃ«n e AvokatisÃ« sÃ« ShqipÃ«risÃ«

âš–ï¸ **Sistemi ligjor shqiptar bazohet nÃ«:**
- KushtetutÃ«n e RepublikÃ«s sÃ« ShqipÃ«risÃ«
- Kodet e ndryshme (Penal, Civil, Pune, etj.)
- Ligjet e veÃ§anta tÃ« miratuara nga Kuvendi

**Kujdes:** Ky Ã«shtÃ« vetÃ«m njÃ« sistem i pÃ«rgjithshÃ«m kÃ«shillimi. PÃ«r Ã§Ã«shtje tÃ« rÃ«ndÃ«sishme ligjore, rekomandohet konsultimi me ekspertÃ« ligjorÃ«.
            """
        
        # If we have documents, provide a basic summary
        response = "ðŸ›ï¸ **Informacion nga Dokumentet Ligjore**\n\n"
        
        for i, doc in enumerate(relevant_docs[:2], 1):
            response += f"**{i}. {doc['title']}**\n"
            response += f"{doc['content'][:300]}...\n\n"
        
        response += "\nâš–ï¸ **Rekomandim:** PÃ«r interpretim tÃ« saktÃ« ligjor, konsultohuni me njÃ« jurist tÃ« kualifikuar."
        
        return response


# Helper functions for backward compatibility
def generate_enhanced_response(query: str, relevant_docs: List[Dict], context: str = "") -> str:
    """Legacy function for backward compatibility"""
    client = CloudLLMClient("gemini")
    return client.generate_response(query, relevant_docs, context)
