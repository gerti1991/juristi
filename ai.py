"""
Cloud LLM Integration for Albanian Legal RAG System
Uses Groq API for advanced response generation with environment variables
"""

import os
import requests
import json
from typing import List, Dict, Optional
import time
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

class CloudLLMClient:
    """Client for cloud-based LLM services using environment variables"""
    
    def __init__(self, provider="groq"):
        """Initialize cloud LLM client with environment variables"""
        self.provider = provider
        self.api_key = self._get_api_key()
        self.base_url = self._get_base_url()
        self.model = self._get_model()
        
    def _get_api_key(self) -> str:
        """Get API key from environment or config"""
        if self.provider == "groq":
            api_key = os.getenv("GROQ_API_KEY")
            if not api_key:
                # Check config.py
                try:
                    import config
                    api_key = getattr(config, 'GROQ_API_KEY', None)
                except ImportError:
                    pass
                
                if not api_key:
                    raise ValueError("âš ï¸ GROQ_API_KEY not found! Please set it in config.py or environment variable.")
            return api_key
        elif self.provider == "huggingface":
            return os.getenv("HUGGINGFACE_API_KEY", "")
        else:
            return ""
    
    def _get_base_url(self) -> str:
        """Get base URL for the provider"""
        if self.provider == "groq":
            return "https://api.groq.com/openai/v1/chat/completions"
        elif self.provider == "huggingface":
            return "https://api-inference.huggingface.co/models/"
        else:
            return ""
    
    def _get_model(self) -> str:
        """Get model name for the provider"""
        if self.provider == "groq":
            return "llama3-8b-8192"  # Fast and good for legal tasks
        elif self.provider == "huggingface":
            return "microsoft/DialoGPT-large"
        else:
            return ""
    
    def generate_response(self, query: str, relevant_docs: List[Dict], context: str = "") -> str:
        """Generate enhanced response using cloud LLM with fallback for no documents"""
        
        if not self.api_key:
            return self._fallback_response(query, relevant_docs)

        try:
            # Check if we have relevant documents
            if not relevant_docs or len(relevant_docs) == 0:
                # Use LLM's general knowledge for Albanian legal questions
                prompt = self._create_general_legal_prompt(query)
                print("â„¹ï¸ Nuk u gjetÃ«n dokumente specifike, duke pÃ«rdorur njohuritÃ« e pÃ«rgjithshme ligjore")
            else:
                # Use documents + LLM knowledge
                prompt = self._create_legal_prompt(query, relevant_docs, context)
            
            if self.provider == "groq":
                return self._groq_request(prompt)
            elif self.provider == "huggingface":
                return self._huggingface_request(prompt)
            else:
                return self._fallback_response(query, relevant_docs)
                
        except Exception as e:
            print(f"âŒ Cloud LLM error: {e}")
            return self._fallback_response(query, relevant_docs)
    
    def _create_general_legal_prompt(self, query: str) -> str:
        """Create prompt for general legal knowledge when no documents found"""
        prompt = f"""
Je njÃ« jurist i specializuar pÃ«r tÃ« drejtÃ«n shqiptare. NjÃ« person tÃ« pyet:

PYETJA: {query}

MeqenÃ«se nuk gjeta dokumente specifike nÃ« bazÃ«n e tÃ« dhÃ«nave, pÃ«rdor njohuritÃ« e tua tÃ« pÃ«rgjithshme pÃ«r tÃ« drejtÃ«n shqiptare pÃ«r t'u pÃ«rgjigjur.

UDHÃ‹ZIME:
1. PÃ«rgjigju nÃ« shqip
2. Jep informacion tÃ« pÃ«rgjithshÃ«m pÃ«r sistemin ligjor shqiptar
3. Sugjeroi qÃ« personi tÃ« kontaktojÃ« njÃ« jurist tÃ« kualifikuar pÃ«r kÃ«shilla specifike
4. Mos jep kÃ«shilla tÃ« detajuara ligjore pa dokumente specifike
5. TÃ« jesh i sinqertÃ« qÃ« informacioni Ã«shtÃ« i pÃ«rgjithshÃ«m

PÃ‹RGJIGJJA:
"""
        return prompt
    
    def _create_legal_prompt(self, query: str, relevant_docs: List[Dict], context: str = "") -> str:
        """Create a specialized prompt for Albanian legal queries"""
        
        # Build context from relevant documents
        doc_context = ""
        for i, doc in enumerate(relevant_docs[:3], 1):
            doc_type = "ğŸŒ Dokument i shkarkuar" if doc.get('document_type') == 'scraped_legal_document' else "ğŸ“š Dokument bazÃ«"
            doc_context += f"\n{i}. {doc_type}: {doc['title']}\n"
            doc_context += f"PÃ«rmbajtja: {doc['content'][:400]}...\n"
        
        prompt = f"""Ti je njÃ« ekspert i ligjit shqiptar. PÃ«rgjigju nÃ« pyetjen e dhÃ«nÃ« bazuar nÃ« dokumentet ligjore tÃ« ofruara.

PYETJA: {query}

DOKUMENTET LIGJORE:
{doc_context}

UDHÃ‹ZIME:
- PÃ«rgjigju nÃ« gjuhÃ«n shqipe
- Jep informacion tÃ« saktÃ« dhe tÃ« bazuar nÃ« dokumentet e dhÃ«na
- PÃ«rdor njÃ« ton profesional dhe tÃ« qartÃ«
- NÃ«se informacioni nuk Ã«shtÃ« i mjaftueshÃ«m, thuaj se duhen kÃ«shilla tÃ« mÃ«tejshme nga njÃ« jurist
- Mos shpik informacion qÃ« nuk gjendet nÃ« dokumentet e dhÃ«na

PÃ‹RGJIGJJA:"""

        return prompt
    
    def _groq_request(self, prompt: str) -> str:
        """Make request to Groq API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": "Je njÃ« asistent i specializuar pÃ«r tÃ« drejtÃ«n shqiptare. PÃ«rgjigju nÃ« mÃ«nyrÃ« tÃ« saktÃ« dhe profesionale."
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "max_tokens": 1000,
            "temperature": 0.2,
            "stream": False
        }
        
        response = requests.post(
            self.base_url,
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            return data["choices"][0]["message"]["content"].strip()
        else:
            raise Exception(f"Groq API error: {response.status_code} - {response.text}")
    
    def _huggingface_request(self, prompt: str) -> str:
        """Make request to Hugging Face API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_length": 500,
                "temperature": 0.3,
                "return_full_text": False
            }
        }
        
        response = requests.post(
            f"{self.base_url}{self.model}",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and len(data) > 0:
                return data[0].get("generated_text", "").strip()
            else:
                return str(data)
        else:
            raise Exception(f"HuggingFace API error: {response.status_code}")
    
    def _fallback_response(self, query: str, relevant_docs: List[Dict]) -> str:
        """Fallback response when cloud LLM is not available"""
        
        if not relevant_docs:
            return """âŒ **Nuk u gjetÃ«n dokumente relevante**
            
Ju lutem provoni:
â€¢ PÃ«rdorni fjalÃ« kyÃ§e tÃ« tjera
â€¢ BÃ«ni pyetjen mÃ« tÃ« qartÃ«
â€¢ Kontrolloni drejtshkrimin

âš–ï¸ PÃ«r kÃ«shilla ligjore tÃ« detajuara, konsultohuni me njÃ« jurist tÃ« kualifikuar."""
        
        # Check for specific query types
        vacation_keywords = ['pushim', 'pushimi', 'vacation', 'leave', 'dit']
        if any(keyword in query.lower() for keyword in vacation_keywords):
            return """ğŸ–ï¸ **Pushimi Vjetor nÃ« ShqipÃ«ri**

Sipas Kodit tÃ« PunÃ«s sÃ« ShqipÃ«risÃ«:
â€¢ ğŸ“… **Total**: 28 ditÃ« kalendarike nÃ« vit
â€¢ âš ï¸ **TÃ« detyrueshme**: 14 ditÃ« qÃ« duhet tÃ« merren gjatÃ« vitit
â€¢ ğŸ”„ **Opsionale**: 14 ditÃ« tÃ« tjera mund tÃ« transferohen
â€¢ ğŸ’° **Me pagesÃ«**: Po, pushimi Ã«shtÃ« me pagesÃ« tÃ« plotÃ«

ğŸ“š **Burim**: Kodi i PunÃ«s i ShqipÃ«risÃ«
âš–ï¸ **ShÃ«nim**: PÃ«r detaje tÃ« mÃ«tejshme, konsultohuni me njÃ« jurist."""
        
        business_keywords = ['biznes', 'themeloj', 'business', 'shoqÃ«ri', 'regjistro']
        if any(keyword in query.lower() for keyword in business_keywords):
            return """ğŸ¢ **Themelimi i Biznesit nÃ« ShqipÃ«ri**

Sipas ligjit shqiptar pÃ«r biznesin:
â€¢ ğŸ“‹ **Regjistrimi**: Qendra KombÃ«tare e Biznesit
â€¢ ğŸ“„ **Dokumentet**: Statutet, aktet themelore
â€¢ ğŸ’¼ **Format**: SH.P.K, SHA, KooperativÃ«, etj.
â€¢ â±ï¸ **KohÃ«zgjatja**: Disa ditÃ« pune

ğŸ“š **Burim**: Ligji pÃ«r Biznesin nÃ« ShqipÃ«ri
âš–ï¸ **ShÃ«nim**: PÃ«r procedura tÃ« detajuara, konsultohuni me njÃ« jurist."""
        
        # General response
        response = "ğŸ“‹ **PÃ«rgjigje bazuar nÃ« dokumentet ligjore shqiptare:**\n\n"
        
        for i, doc in enumerate(relevant_docs[:2], 1):
            doc_type = "ğŸŒ" if doc.get('document_type') == 'scraped_legal_document' else "ğŸ“š"
            response += f"{doc_type} **{doc['title']}** (Relevanca: {doc.get('similarity', 0):.2f})\n"
            response += f"ğŸ“„ {doc['content'][:200]}...\n\n"
        
        response += "âš–ï¸ **ShÃ«nim**: Ky informacion Ã«shtÃ« pÃ«r qÃ«llime informuese. "
        response += "PÃ«r kÃ«shilla tÃ« detajuara ligjore, konsultohuni me njÃ« jurist tÃ« kualifikuar."
        
        return response
    
    def test_connection(self) -> bool:
        """Test if the cloud LLM connection works"""
        try:
            test_query = "Test"
            test_docs = [{
                'title': 'Test Document',
                'content': 'This is a test document.',
                'document_type': 'hardcoded'
            }]
            
            response = self.generate_response(test_query, test_docs)
            return len(response) > 10  # Basic check
            
        except Exception as e:
            print(f"âŒ Connection test failed: {e}")
            return False


def main():
    """Test the cloud LLM integration"""
    print("ğŸŒ Testing Cloud LLM Integration")
    print("=" * 50)
    
    # Initialize client
    client = CloudLLMClient("groq")
    print(f"âœ… Client initialized for {client.provider}")
    print(f"ğŸ”‘ API Key: {'âœ… Available' if client.api_key else 'âŒ Missing'}")
    print(f"ğŸ¤– Model: {client.model}")
    
    # Test connection
    print("\nğŸ” Testing connection...")
    if client.test_connection():
        print("âœ… Connection successful!")
    else:
        print("âŒ Connection failed, will use fallback responses")
    
    # Test with Albanian legal query
    print("\nğŸ“‹ Testing with Albanian legal query...")
    test_query = "Sa dit pushimi kam nÃ« punÃ« tÃ« detyrueshme?"
    test_docs = [{
        'title': 'Kodi i PunÃ«s - Labor Code',
        'content': 'Kodi i PunÃ«s rregullon marrÃ«dhÃ«niet e punÃ«s, tÃ« drejtat dhe detyrimet e punÃ«dhÃ«nÃ«sve dhe tÃ« punÃ«suarve. Ã‡do punÃ«tor ka tÃ« drejtÃ« pÃ«r pushim vjetor me pagesÃ«. Pushimi vjetor Ã«shtÃ« gjithsej 28 ditÃ« kalendarike nÃ« vit.',
        'document_type': 'hardcoded',
        'similarity': 0.85
    }]
    
    print(f"â“ Query: {test_query}")
    response = client.generate_response(test_query, test_docs)
    print(f"\nğŸ’¬ Response:\n{response}")
    
    print("\nğŸ‰ Cloud LLM integration test completed!")


if __name__ == "__main__":
    main()
